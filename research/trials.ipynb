{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone a GITHUB Repo ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/deltae/Source-Code-Analysis-RAG/research'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir test_repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"/Users/deltae/Source-Code-Analysis-RAG/research/test_repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<git.repo.base.Repo '/Users/deltae/Source-Code-Analysis-RAG/research/test_repo/.git'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repo.clone_from(\"https://github.com/architthakur2000/Convulational-Neural-Networks.git\", to_path=repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(repo_path, glob = \"**/*\", suffixes = [\".py\"], parser = LanguageParser(language=Language.PYTHON, parser_threshold=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# python imports\\nimport os\\nimport time\\nimport argparse\\nfrom tqdm import tqdm\\n\\n# torch imports\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\n\\n# helper functions for computer vision\\nimport torchvision\\nimport torchvision.transforms as transforms\\n\\nfrom dataloader import MiniPlaces\\nfrom student_code import LeNet, test_model\\n\\n\\n# main function for training and testing\\ndef main(args):\\n    # set up random seed\\n    torch.manual_seed(0)\\n\\n    ###################################\\n    # setup model                     #\\n    ###################################\\n    model = LeNet()\\n    # set up transforms to transform the PIL Image to tensors\\n    test_transform = transforms.Compose([\\n        transforms.ToTensor(),\\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\\n                             std=[0.229, 0.224, 0.225])\\n    ])\\n\\n    ################################\\n    # setup dataset and dataloader #\\n    ################################\\n    data_folder = \\'./data\\'\\n    os.makedirs(os.path.expanduser(data_folder), exist_ok=True)\\n    test_set = MiniPlaces(\\n        root=data_folder, split=\"val\", download=True, transform=test_transform)\\n    test_loader = torch.utils.data.DataLoader(\\n        test_set, batch_size=32, shuffle=False)\\n\\n    ################################\\n    # evaluating the model         #\\n    ################################\\n    # load from a previous model\\n    if not args.load:\\n        args.load = \"./outputs/model_best.pth.tar\"\\n\\n    if os.path.isfile(args.load):\\n        print(\"=> loading checkpoint \\'{:s}\\'\".format(args.load))\\n        checkpoint = torch.load(args.load)\\n        # load model weight\\n        model.load_state_dict(checkpoint[\\'state_dict\\'])\\n        epoch = checkpoint[\\'epoch\\']\\n        print(\"=> loaded checkpoint \\'{:s}\\' (epoch {:d})\".format(\\n            args.load, checkpoint[\\'epoch\\']))\\n    else:\\n        print(\"=> no checkpoint found at \\'{}\\'\".format(args.load))\\n        return\\n\\n    # evalution and timing\\n    print(\"Evaluting the model ...\\\\n\")\\n    start = time.time()\\n    # evaluate the loaded model\\n    acc = test_model(model, test_loader, epoch-1)\\n    end = time.time()\\n    print(\"Evaluation took {:0.2f} sec\".format(end - start))\\n\\n\\nif __name__ == \\'__main__\\':\\n    parser = argparse.ArgumentParser(description=\\'Image Classification using Pytorch\\')\\n    parser.add_argument(\\'--load\\', default=\\'\\', type=str, metavar=\\'PATH\\',\\n                        help=\\'path to latest checkpoint (default: none)\\')\\n    args = parser.parse_args()\\n    main(args)\\n', metadata={'source': '/Users/deltae/Source-Code-Analysis-RAG/research/test_repo/eval_miniplaces.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='# python imports\\nimport os\\nfrom tqdm import tqdm\\n\\n# torch imports\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\n\\n# helper functions for computer vision\\nimport torchvision\\nimport torchvision.transforms as transforms\\n\\n\\nclass LeNet(nn.Module):\\n    def __init__(self, input_shape=(32, 32), num_classes=100):\\n        super(LeNet, self).__init__()\\n        \\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\\n        \\n        self.max_pool_1 = nn.MaxPool2d(kernel_size=2, padding = 0, stride=2)\\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\\n        self.max_pool_2 = nn.MaxPool2d(kernel_size=2, padding = 0, stride=2)\\n\\n        torch.nn.Flatten()\\n        self.fc1 = nn.Linear(16 * (input_shape[0] // 4-3) * (input_shape[1] //4-3), 256)\\n        self.fc2 = nn.Linear(256,128)\\n        self.fc3 = nn.Linear(128, num_classes)\\n\\n    def forward(self, x):\\n        shape_dict = {}\\n        # certain operations\\n        \\n        #max pooling with 2X2 grid.\\n        out = torch.nn.functional.relu(self.conv1(x))\\n        out = self.max_pool_1(out)\\n        shape_dict[1] = list(out.size())\\n\\n        out = torch.nn.functional.relu(self.conv2(out))\\n        out = self.max_pool_2(out)\\n        shape_dict[2] = list(out.size())\\n       \\n        #convule, then perform ReLU non-linearity\\n        \\n        \\n        out = out.view(-1, (16*5*5))\\n        shape_dict[3] = list(out.size())    \\n        \\n        out = torch.nn.functional.relu(self.fc1(out))\\n        shape_dict[4] = list(out.size())\\n        out = torch.nn.functional.relu(self.fc2(out))\\n        shape_dict[5] = list(out.size()) \\n        out = self.fc3(out)\\n        shape_dict[6] = list(out.size())\\n\\n        return out, shape_dict\\n\\n\\ndef count_model_params():\\n    \\'\\'\\'\\n    return the number of trainable parameters of LeNet.\\n    \\'\\'\\'\\n    model = LeNet()\\n    model_params = list(model.named_parameters()).__len__()\\n\\n    return model_params\\n\\n\\ndef train_model(model, train_loader, optimizer, criterion, epoch):\\n    \"\"\"\\n    model (torch.nn.module): The model created to train\\n    train_loader (pytorch data loader): Training data loader\\n    optimizer (optimizer.*): A instance of some sort of optimizer, usually SGD\\n    criterion (nn.CrossEntropyLoss) : Loss function used to train the network\\n    epoch (int): Current epoch number\\n    \"\"\"\\n    model.train()\\n    train_loss = 0.0\\n    for input, target in tqdm(train_loader, total=len(train_loader)):\\n        ###################################\\n        # fill in the standard training loop of forward pass,\\n        # backward pass, loss computation and optimizer step\\n        ###################################\\n\\n        # 1) zero the parameter gradients\\n        optimizer.zero_grad()\\n        # 2) forward + backward + optimize\\n        output, _ = model(input)\\n        loss = criterion(output, target)\\n        loss.backward()\\n        optimizer.step()\\n\\n        # Update the train_loss variable\\n        # .item() detaches the node from the computational graph\\n        # Uncomment the below line after you fill block 1 and 2\\n        train_loss += loss.item()\\n\\n    train_loss /= len(train_loader)\\n    print(\\'[Training set] Epoch: {:d}, Average loss: {:.4f}\\'.format(epoch+1, train_loss))\\n\\n    return train_loss\\n\\n\\ndef test_model(model, test_loader, epoch):\\n    model.eval()\\n    correct = 0\\n    with torch.no_grad():\\n        for input, target in test_loader:\\n            output, _ = model(input)\\n            pred = output.max(1, keepdim=True)[1]\\n            correct += pred.eq(target.view_as(pred)).sum().item()\\n\\n    test_acc = correct / len(test_loader.dataset)\\n    print(\\'[Test set] Epoch: {:d}, Accuracy: {:.2f}%\\\\n\\'.format(\\n        epoch+1, 100. * test_acc))\\n\\n    return test_acc\\n', metadata={'source': '/Users/deltae/Source-Code-Analysis-RAG/research/test_repo/student_code.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='# python imports\\nimport os\\nimport pickle\\nimport hashlib\\nimport urllib\\nimport tarfile\\nimport shutil\\nimport time\\nfrom PIL import Image\\nfrom tqdm import tqdm\\n\\n# torch imports\\nimport torch\\nfrom torch.utils import data\\n\\n\\ndata_urls = {\"data\": \"http://6.869.csail.mit.edu/fa17/miniplaces/data.tar.gz\",\\n             \"train\": \"http://raw.githubusercontent.com/CSAILVision/miniplaces/master/data/train.txt\",\\n             \"val\": \"http://raw.githubusercontent.com/CSAILVision/miniplaces/master/data/val.txt\"}\\ndata_md5 = \"265825ec94f79390e4f1e38045a69059\"\\n\\n\\ndef calculate_md5(fpath, chunk_size=1024*1024):\\n    md5 = hashlib.md5()\\n    with open(fpath, \\'rb\\') as f:\\n        for chunk in iter(lambda: f.read(chunk_size), b\\'\\'):\\n            md5.update(chunk)\\n    return md5.hexdigest()\\n\\ndef gen_bar_updater():\\n    pbar = tqdm(total=None)\\n\\n    def bar_update(count, block_size, total_size):\\n        if pbar.total is None and total_size:\\n            pbar.total = total_size\\n        progress_bytes = count * block_size\\n        pbar.update(progress_bytes - pbar.n)\\n\\n    return bar_update\\n\\ndef download_url(url, folder):\\n    \"\"\"Download a file from a url and place it in folder.\\n    Args:\\n        url (str): URL to download file from\\n        folder (str): Directory to place downloaded file in\\n    \"\"\"\\n    fpath = os.path.join(os.path.expanduser(folder),\\n                         os.path.basename(url))\\n\\n    os.makedirs(os.path.expanduser(folder), exist_ok=True)\\n\\n    if os.path.exists(fpath):\\n        return\\n\\n    try:\\n        print(\\'Downloading \\' + url + \\' to \\' + fpath)\\n        urllib.request.urlretrieve(\\n            url, fpath,\\n            reporthook=gen_bar_updater()\\n        )\\n    except (urllib.error.URLError, IOError) as err:\\n        print(\\'Failed download.\\')\\n        raise err\\n    return\\n\\ndef extract_targz(src_file, dst_path):\\n    # create dst folder / extract all files\\n    print(\\'Extracting \\' + src_file + \\' to\\' + dst_path)\\n    os.makedirs(os.path.expanduser(dst_path), exist_ok=True)\\n    with tarfile.open(src_file, \\'r:gz\\') as tar:\\n        tar.extractall(path=dst_path)\\n\\nclass MiniPlaces(data.Dataset):\\n    \"\"\"\\n    A simple dataloader for mini places\\n    \"\"\"\\n    def __init__(self,\\n                 root,\\n                 label_file=None,\\n                 num_classes=100,\\n                 download=False,\\n                 split=\"train\",\\n                 transform=None):\\n        assert split in [\"train\", \"val\", \"test\"]\\n        # root folder, split\\n        self.root_folder = os.path.join(root, \"miniplaces\")\\n        self.split = split\\n        self.transform = transform\\n        self.n_classes = num_classes\\n\\n        # download dataset\\n        if download:\\n            self._download_dataset(root)\\n\\n        # load all labels\\n        if label_file is None:\\n            label_file = os.path.join(self.root_folder, split + \\'.txt\\')\\n        if not os.path.exists(label_file):\\n            raise ValueError(\\n                \\'Label file {:s} does not exist!\\'.format(label_file))\\n        with open(label_file) as f:\\n            lines = f.readlines()\\n\\n        # store the file list\\n        file_label_list = []\\n        for line in lines:\\n            filename, label_id = line.rstrip(\\'\\\\n\\').split(\\' \\')\\n            label_id = int(label_id)\\n            filename = os.path.join(self.root_folder, filename)\\n            file_label_list.append((filename, label_id))\\n\\n        self.img_label_list = self._load_dataset(file_label_list)\\n\\n    def _download_dataset(self, data_folder):\\n        # data folder and data file\\n        data_folder = os.path.expanduser(data_folder)\\n        data_file = os.path.join(data_folder,\\n                                 os.path.basename(data_urls[\\'data\\']))\\n\\n        # if we need to download the full dataset\\n        require_download = True\\n        if os.path.exists(data_file):\\n            file_md5 = calculate_md5(data_file)\\n        else:\\n            file_md5 = None\\n        if file_md5 == data_md5:\\n            require_download = False\\n\\n        if (not require_download) and \\\\\\n           os.path.exists(os.path.join(data_folder, \\'miniplaces\\')):\\n            # only download the annotations\\n            download_url(data_urls[self.split],\\n                         os.path.join(data_folder, \\'miniplaces\\'))\\n        else:\\n            # corner case: a corrupted file\\n            if os.path.exists(data_file) and (file_md5 != data_md5):\\n                print(\"File corrupted. Remove and re-download ...\")\\n                os.remove(data_file)\\n            # corner case: the subfolder already exists\\n            if os.path.exists(os.path.join(data_folder, \\'miniplaces\\')):\\n                shutil.rmtree(os.path.join(data_folder, \\'miniplaces\\'))\\n            # download and extract the tar.gz file\\n            download_url(data_urls[\\'data\\'], data_folder)\\n            extract_targz(data_file, data_folder)\\n            # setup the folders\\n            print(\"Setting up data folders ...\")\\n            shutil.move(os.path.join(data_folder, \\'images\\'),\\n                        os.path.join(data_folder, \\'miniplaces\\'))\\n            shutil.rmtree(os.path.join(data_folder, \\'objects\\'))\\n            # download the annotations\\n            download_url(data_urls[self.split],\\n                         os.path.join(data_folder, \\'miniplaces\\'))\\n        return\\n\\n    def _load_dataset(self, file_label_list):\\n        cached_filename = os.path.join(self.root_folder,\\n                                       \\'cached_{:s}.pkl\\'.format(self.split))\\n        if os.path.exists(cached_filename):\\n            # load dataset into memory\\n            print(\"=> Loading from cached file {:s} ...\".format(cached_filename))\\n            try:\\n                img_label_list = pickle.load(open(cached_filename, \"rb\"))\\n            except (RuntimeError, TypeError, NameError):\\n                print(\"Can\\'t load cached file. Please remove the file and rebuild the cache!\")\\n        else:\\n            # load dataset into memory\\n            print(\"Loading {:s} set into memory. This might take a while ...\".format(self.split))\\n            img_label_list = tuple()\\n            for filename, label_id in tqdm(file_label_list):\\n                img = Image.open(filename).convert(\\'RGB\\')\\n                img = img.resize((32, 32), Image.BILINEAR)\\n                label = label_id\\n                img_label_list += ((img, label), )\\n            pickle.dump(img_label_list, open(cached_filename, \"wb\"))\\n        return img_label_list\\n\\n    def __len__(self):\\n        return len(self.img_label_list)\\n\\n    def __getitem__(self, index):\\n        # load img and label\\n        img, label = self.img_label_list[index]\\n\\n        # apply data augmentation\\n        if self.transform is not None:\\n            img = self.transform(img)\\n        return img, label\\n\\n    def get_index_mapping(self):\\n        # load the train label file\\n        train_label_file = os.path.join(self.root_folder, self.split + \\'.txt\\')\\n        if not os.path.exists(train_label_file):\\n            raise ValueError(\\n                \\'Label file {:s} does not exist!\\'.format(train_label_file))\\n        with open(train_label_file) as f:\\n            lines = f.readlines()\\n\\n        # get the category names\\n        id_index_map = {}\\n        for line in lines:\\n            filename, label_id = line.rstrip(\\'\\\\n\\').split(\\' \\')\\n            cat_name = filename.split(\\'/\\')[-2]\\n            id_index_map[label_id] = cat_name\\n\\n        # return a dictionary that maps an ID to its category name\\n        return id_index_map\\n', metadata={'source': '/Users/deltae/Source-Code-Analysis-RAG/research/test_repo/dataloader.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='# python imports\\nimport os\\nimport argparse\\nfrom tqdm import tqdm\\n\\n# torch imports\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\n\\n# helper functions for computer vision\\nimport torchvision\\nimport torchvision.transforms as transforms\\n\\nfrom dataloader import MiniPlaces\\nfrom student_code import LeNet, train_model, test_model\\n\\n\\ndef save_checkpoint(state, is_best,\\n                    file_folder=\"./outputs/\",\\n                    filename=\\'checkpoint.pth.tar\\'):\\n    \"\"\"save checkpoint\"\"\"\\n    if not os.path.exists(file_folder):\\n        os.makedirs(os.path.expanduser(file_folder), exist_ok=True)\\n    torch.save(state, os.path.join(file_folder, filename))\\n    if is_best:\\n        # skip the optimization state\\n        state.pop(\\'optimizer\\', None)\\n        torch.save(state, os.path.join(file_folder, \\'model_best.pth.tar\\'))\\n\\n\\n# main function for training and testing\\ndef main(args):\\n    # set up random seed\\n    torch.manual_seed(0)\\n\\n    ###################################\\n    # setup model, loss and optimizer #\\n    ###################################\\n    model = LeNet()\\n\\n    training_criterion = nn.CrossEntropyLoss()\\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\\n    # optim.Adam(model.parameters(), lr=args.lr)\\n\\n    # set up transforms to transform the PIL Image to tensors\\n    train_transform = transforms.Compose([\\n        transforms.ToTensor(),\\n        transforms.RandomHorizontalFlip(),\\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\\n                             std=[0.229, 0.224, 0.225])\\n    ])\\n\\n    test_transform = transforms.Compose([\\n        transforms.ToTensor(),\\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\\n                             std=[0.229, 0.224, 0.225])\\n    ])\\n\\n    ################################\\n    # setup dataset and dataloader #\\n    ################################\\n    data_folder = \\'./data\\'\\n    if not os.path.exists(data_folder):\\n        os.makedirs(os.path.expanduser(data_folder), exist_ok=True)\\n\\n    train_set = MiniPlaces(\\n        root=data_folder, split=\"train\", download=True, transform=train_transform)\\n    test_set = MiniPlaces(\\n        root=data_folder, split=\"val\", download=True, transform=test_transform)\\n\\n    train_loader = torch.utils.data.DataLoader(\\n        train_set, batch_size=args.batch_size, shuffle=True)\\n    test_loader = torch.utils.data.DataLoader(\\n        test_set, batch_size=args.batch_size, shuffle=False)\\n\\n    ################################\\n    # start the training           #\\n    ################################\\n    # resume from a previous checkpoint\\n    best_acc = 0.0\\n    start_epoch = 0\\n    if args.resume:\\n        if os.path.isfile(args.resume):\\n            print(\"=> loading checkpoint \\'{:s}\\'\".format(args.resume))\\n            checkpoint = torch.load(args.resume)\\n            start_epoch = checkpoint[\\'epoch\\']\\n            best_acc = checkpoint[\\'best_acc\\']\\n            # load model weight\\n            model.load_state_dict(checkpoint[\\'state_dict\\'])\\n            # load optimizer states\\n            optimizer.load_state_dict(checkpoint[\\'optimizer\\'])\\n            print(\"=> loaded checkpoint \\'{:s}\\' (epoch {:d}, acc {:0.2f})\".format(\\n                args.resume, checkpoint[\\'epoch\\'], 100*best_acc))\\n        else:\\n            print(\"=> no checkpoint found at \\'{}\\'\".format(args.resume))\\n            return\\n\\n    # training of the model\\n    print(\"Training the model ...\\\\n\")\\n    for epoch in range(start_epoch, args.epochs):\\n        # train model for 1 epoch\\n        train_model(model, train_loader, optimizer, training_criterion, epoch)\\n        # evaluate the model on test_set after this epoch\\n        acc = test_model(model, test_loader, epoch)\\n        # save the current checkpoint\\n        save_checkpoint({\\n            \\'epoch\\': epoch + 1,\\n            \\'state_dict\\': model.state_dict(),\\n            \\'best_acc\\' : max(best_acc, acc),\\n            \\'optimizer\\' : optimizer.state_dict(),\\n            }, (acc > best_acc))\\n        best_acc = max(best_acc, acc)\\n    print(\"Finished Training\")\\n\\n\\nif __name__ == \\'__main__\\':\\n    parser = argparse.ArgumentParser(description=\\'Image Classification using Pytorch\\')\\n    parser.add_argument(\\'--epochs\\', default=10, type=int, metavar=\\'N\\',\\n                        help=\\'number of total epochs to run\\')\\n    parser.add_argument(\\'--lr\\', default=0.001, type=float,\\n                        metavar=\\'LR\\', help=\\'initial learning rate\\', dest=\\'lr\\')\\n    parser.add_argument(\\'--batch-size\\', default=32, type=int, metavar=\\'N\\',\\n                        help=\\'number of images within a mini-batch\\')\\n    parser.add_argument(\\'--resume\\', default=\\'\\', type=str, metavar=\\'PATH\\',\\n                        help=\\'path to latest checkpoint (default: none)\\')\\n    args = parser.parse_args()\\n    main(args)\\n', metadata={'source': '/Users/deltae/Source-Code-Analysis-RAG/research/test_repo/train_miniplaces.py', 'language': <Language.PYTHON: 'python'>})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking and Splitting ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.PYTHON, chunk_size = 2000, chunk_overlap = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = documents_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(texts, embedding=embeddings, persist_directory=\"./sca_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=llm, memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(llm, retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":3}), memory=memory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain the train_model function in student_code.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 16, updating n_results = 16\n"
     ]
    }
   ],
   "source": [
    "result = chain(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `train_model` function in the provided code snippet is used for training a PyTorch model. It takes the model, training data loader, optimizer, loss function (criterion), and the current epoch number as input. Inside the function, it performs the standard training loop steps which include forward pass, backward pass, loss computation, and optimizer step to update the model parameters.\n",
      "\n",
      "Here is a brief overview of the key steps within the `train_model` function:\n",
      "1. Sets the model to training mode.\n",
      "2. Iterates through the training data loader to process each batch.\n",
      "3. Computes the loss based on the model's output and the target labels.\n",
      "4. Backpropagates the loss to compute gradients and updates the model's parameters using the optimizer.\n",
      "5. Tracks and accumulates the training loss for each epoch.\n",
      "6. Prints the average training loss for the current epoch.\n",
      "\n",
      "Overall, the `train_model` function is responsible for training the model over multiple epochs by iterating through the training data loader and updating the model's parameters based on the calculated loss and optimizer.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
